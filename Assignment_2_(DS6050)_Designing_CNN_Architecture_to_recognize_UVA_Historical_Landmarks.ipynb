{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4u4YC8iqxpe"
   },
   "source": [
    "# Recognizing UVA landmarks with neural nets (75 pts)\n",
    "![UVA Grounds](https://sworld.co.uk/img/img/131/photoAlbum/5284/originals/0.jpg)\n",
    "\n",
    "The UVA Grounds is known for its Jeffersonian architecture and place in U.S. history as a model for college and university campuses throughout the country. Throughout its history, the University of Virginia has won praises for its unique Jeffersonian architecture.\n",
    "\n",
    "In this assignment, you will attempt the build an image recognition system to classify different buildlings/landmarks on Grounds. You will earn 75 points for this assignment plus 10 bonus points if (1) your classifier performs exceed 94% accuracy.\n",
    "\n",
    "To make it easier for you, some codes have been provided to help you process the data, you may modify it to fit your needs. You must submit the .ipynb file via UVA Canvas with the following format: yourcomputingID_assignment_2.ipynb\n",
    "\n",
    "Best of luck, and have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUboEeI0CH0A"
   },
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bIAunzfaCNAH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 21:30:15.503014: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-01 21:30:15.956281: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(42) # note that you must use the same seed to ensure consistentcy in your training/validation/testing\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whpECRG_B2Nj"
   },
   "source": [
    "# Import Dataset\n",
    "The full dataset is huge (+37GB) with +13K images of 18 classes. So it will take a while to download, extract, and process. To save you time and effort, a subset of the data has been resized and compressed to only 379Mb and stored in my Firebase server. This dataset will be the one you will benchmark for your grade. If you are up for a challenge (and perhaps bonus points), contact the instructor for the full dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4E5kiDN9OFs",
    "outputId": "394ce0ff-6297-4454-e21a-f37e434d1195"
   },
   "outputs": [],
   "source": [
    "# Download dataset from FirebaseStorage\n",
    "!wget https://firebasestorage.googleapis.com/v0/b/uva-landmark-images.appspot.com/o/dataset.zip?alt=media&token=e1403951-30d6-42b8-ba4e-394af1a2ddb7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKWszcAd9WJh",
    "outputId": "df695045-ee28-4800-e6b0-f4cf915a096e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /content/dataset.zip?alt=media, /content/dataset.zip?alt=media.zip or /content/dataset.zip?alt=media.ZIP.\n",
      "\n",
      "No zipfiles found.\n"
     ]
    }
   ],
   "source": [
    "# Extract content\n",
    "!unzip \"/content/dataset.zip?alt=media\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "474nVh3m-FrM",
    "outputId": "a833aa71-4683-4743-e9e9-8fc533d89b11"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_files\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;66;03m# progress bar\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/dataset/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m;\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "data_dir = \"/content/dataset/\"\n",
    "batch_size = 32;\n",
    "# IMPORTANT: Depends on what pre-trained model you choose, you will need to change these dimensions accordingly\n",
    "img_height = 150;\n",
    "img_width = 150;\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 42,\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation Dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 42,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Gb87iBmZGNOF",
    "outputId": "ebb5bf3f-cbe9-4ada-dc1a-5a494d2ae6d9"
   },
   "outputs": [],
   "source": [
    "# Visualize some of the train samples of one batch\n",
    "# Make sure you create the class names that match the order of their appearances in the \"files\" variable\n",
    "class_names = ['AcademicalVillage', 'AldermanLibrary', 'AlumniHall', 'AquaticFitnessCenter',\n",
    "  'BavaroHall', 'BrooksHall', 'ClarkHall', 'MadisonHall', 'MinorHall', 'NewCabellHall',\n",
    "  'NewcombHall', 'OldCabellHall', 'OlssonHall', 'RiceHall', 'Rotunda', 'ScottStadium',\n",
    "  'ThorntonHall', 'UniversityChapel']\n",
    "\n",
    "# Rows and columns are set to fit one training batch (32)\n",
    "n_rows = 8\n",
    "n_cols = 4\n",
    "plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range (n_rows*n_cols):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[labels[i]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=.2, hspace=.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7tg1WteYWKi"
   },
   "source": [
    "# It's your turn: Building a classifier for UVA Landmark Dataset\n",
    "You may design your own architecture AND re-use any of the exising frameworks.\n",
    "\n",
    "Best of luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kP0-jzrMYioK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE STARTS HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Tensorflow 2.13.0",
   "language": "python",
   "name": "tensorflow-2.13.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
